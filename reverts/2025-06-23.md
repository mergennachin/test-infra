# Week of 2025-06-23 to 2025-06-30 (30)

### GHFirst (13)

- [Revert "[dynamo] fix _torchdynamo_orig_callable naming issues (#156901)"](https://github.com/pytorch/pytorch/commit/1e4c5b666afe6434cbe3b830aaf70864074d40f5)
  - Sorry for reverting your change but it seems to break some internal tests D77411594 ([comment](https://github.com/pytorch/pytorch/pull/156901#issuecomment-3014734151))
- [Revert "python definitely_contiguous-> is_contiguous_or_false (#156515)"](https://github.com/pytorch/pytorch/commit/75a7d9e86842b57f9001a0fa6fd716927614dbf9)
  - Sorry for reverting your change but it seems to cause some torch.export failures internally ([comment](https://github.com/pytorch/pytorch/pull/156515#issuecomment-3014104570))
- [Revert "Rename torch::standalone to headeronly (#156964)"](https://github.com/pytorch/pytorch/commit/e290a4c645e00926f0bfa44488f9f7dbd7cb2d0b)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/156964#issuecomment-3011136947))
- [Revert "Fix silent incorrectness arising from incorrect alias information (#152011)"](https://github.com/pytorch/pytorch/commit/e3977e843de6c9c43be00ee8c67c533debfc0dc9)
  - cannot land internally. owner will update and reland to fix ([comment](https://github.com/pytorch/pytorch/pull/152011#issuecomment-3010723960))
- [Revert "[dynamo] fix segfault due to dangling CacheEntry backend pointer (#156527)"](https://github.com/pytorch/pytorch/commit/9fe2d156a9f81d67e248c0edaf7feee1a8d6c4d5)
  - failing test assertions ([comment](https://github.com/pytorch/pytorch/pull/156527#issuecomment-3009231797))
- [Revert "[cond] support gen_schema for cond (#154193)"](https://github.com/pytorch/pytorch/commit/21990fbad97acec769f737b450033774c7be8737)
  - issue landing internally, discussed with Yidi offline ([comment](https://github.com/pytorch/pytorch/pull/154193#issuecomment-3009160081))
- [Revert "Add DeviceAllocator as the base device allocator (#138222)"](https://github.com/pytorch/pytorch/commit/3dd872e6d53560933d8d7fc11357617746d37168)
  - internal build failures ([comment](https://github.com/pytorch/pytorch/pull/138222#issuecomment-3002206756))
- [Revert "Add unified memory APIs for torch.accelerator (#152932)"](https://github.com/pytorch/pytorch/commit/6459a5c7a92e7a38db374780b91116cc958b6af9)
  - internal build failures ([comment](https://github.com/pytorch/pytorch/pull/138222#issuecomment-3002206756))
- [Revert "Add fx_graph_runnable tests boilerplate (#156552)"](https://github.com/pytorch/pytorch/commit/4bd18e31e5a38d0e84ce915b1fa124058c6373fa)
  - breaking internal ([comment](https://github.com/pytorch/pytorch/pull/156552#issuecomment-3002159473))
- [Revert "Remove remaining CUDA 12.4 CI code (#155412)"](https://github.com/pytorch/pytorch/commit/aa280ea19fb20923d048909fa98af092e18ca2fb)
  - cuda 12.4 still needed ([comment](https://github.com/pytorch/pytorch/pull/155412#issuecomment-3001711830))
- [Revert "[invoke_subgraph] make same subgraph share get_attr target (#156260)"](https://github.com/pytorch/pytorch/commit/d061a02e6ecf3b62f409578c7d05a564264d1288)
  - no signal, it breaks linter tests. ([comment](https://github.com/pytorch/pytorch/pull/156260#issuecomment-2997478798))
- [Revert "[invoke_subgraph] make collect_meta_analysis fake prop cachable (#156347)"](https://github.com/pytorch/pytorch/commit/35d03398e511fa0921c9db928c661dc9531ff2fc)
  - no signal, it breaks linter tests. ([comment](https://github.com/pytorch/pytorch/pull/156347#issuecomment-2997453729))
- [Revert "[dynamo] fixes to lru_cache message and adding user stack trace in debug mode (#156463)"](https://github.com/pytorch/pytorch/commit/55ef7b15e0b2de903bfc26adfb0788ecfbcb4ed4)
  - This is temoprary revert, to restore diff train sync. We should be good to reland this change ([comment](https://github.com/pytorch/pytorch/pull/156463#issuecomment-2997335541))

### Ignored Signal (3)

- [Revert "[BE] use `pathlib.Path` instead of `os.path.*` in `setup.py` (#156742)"](https://github.com/pytorch/pytorch/commit/29f76ec0f3eccf619a0aee03e3abbd4914a1b4b2)
  - Looks like it broke all ROCM tests, see https://hud.pytorch.org/hud/pytorch/pytorch/721d2580dbf9a4922adc1c7d1cc8237126d3cdd6/1?per_page=50&name_filter=inductor-rocm&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/156742#issuecomment-3016937704))
- [Revert "[dynamo] Better error for invalid @contextlib.contextmanager usage (#156924)"](https://github.com/pytorch/pytorch/commit/56c69bedcc7e2211e5a3d6249e51b1674be5d10e)
  - Likely same issue as #156963 ([comment](https://github.com/pytorch/pytorch/pull/156924#issuecomment-3011087802))
- [Revert "[dynamo] Improve error message for cond aliasing (#156963)"](https://github.com/pytorch/pytorch/commit/6215e90b7b9af8275c5dbfaa5fd58d7ec08b6764)
  - Sorry for reverting your PR, but the failures are legit ([comment](https://github.com/pytorch/pytorch/pull/156963#issuecomment-3010870664))

### Not through pytorchbot (1)

- [Revert "[dynamo] handle fullgraph toggle using nested torch.compile (#155166)" (#156624)](https://github.com/pytorch/pytorch/commit/ee4d343499c80be16a58d5ac604da6e2130cd94d)

### No Signal (12)

- [Revert "[BE] parse CMake version from `cmake -E capabilities` instead of `cmake --version` (#157073)"](https://github.com/pytorch/pytorch/commit/2eb744c08d600e84b167dbda7daa792243a2c235)
  - break libtorch build on Windows ([comment](https://github.com/pytorch/pytorch/pull/157073#issuecomment-3015273679))
- [Revert "[schema_upgrader] add C++ upgrader for json based upgrading (#156761)"](https://github.com/pytorch/pytorch/commit/f810480dbefabbff6cf0852c9f610f84dd440b8d)
  - break linter test, which doesn't show up in the pr ([comment](https://github.com/pytorch/pytorch/pull/156761#issuecomment-3014918800))
- [Revert "Fixes for CPython int/float tests (#155978)"](https://github.com/pytorch/pytorch/commit/0decd966af9cdcb7ab4410cf475d2fc09f2dea0c)
  - Some tests are still failing in trunk ([comment](https://github.com/pytorch/pytorch/pull/155978#issuecomment-3014185210))
- [Revert "Fix reinplace pass handling of view input + mutable custom op (#156729)"](https://github.com/pytorch/pytorch/commit/4a80ddfbe70bf6b75acc3177e5d2095b285da841)
  - breaks lint: [GH job link](https://github.com/pytorch/pytorch/actions/runs/15918483073/job/44900430950) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/b754b1fa43d20f5b31e17c396487ab56991912da) ([comment](https://github.com/pytorch/pytorch/pull/156729#issuecomment-3011867746))
- [Revert "[Quant][CPU] fix fake_quantize_per_tensor_affine of inf values (#155109)"](https://github.com/pytorch/pytorch/commit/029e2b05c225588098d3eba445fd04189691f77d)
  - The corresponding test still breaks on rocm ([comment](https://github.com/pytorch/pytorch/pull/155109#issuecomment-3004698438))
- [Revert "[logging] dynamo_timed for CachingAutotuner.coordinate_descent_tuning (#156517)"](https://github.com/pytorch/pytorch/commit/fd4bb29410c035b31ca55262c3012cadb1194aae)
  - internal reverted ([comment](https://github.com/pytorch/pytorch/pull/156517#issuecomment-3002172049))
- [Revert "[dynamo] Graph break on `torch.Tensor.data` assignment with mismatched dtype (#156623)"](https://github.com/pytorch/pytorch/commit/1dc1eedd4369f6e6bb79d5315e3ffc1bdc59b709)
  - Breaks Dynamo tests in trunk ([comment](https://github.com/pytorch/pytorch/pull/156623#issuecomment-3001806841))
- [Revert "Simplify nvtx3 CMake handling, always use nvtx3 (#153784)"](https://github.com/pytorch/pytorch/commit/19f851ce10b16f0ed11d18d937ca7b32746153b0)
  - breaking internal tests and cuda 12.4 builds still used in CI ([comment](https://github.com/pytorch/pytorch/pull/153784#issuecomment-3001702310))
- [Revert "[aotd] Support mutations of the same input in fw and bw (#155354)"](https://github.com/pytorch/pytorch/commit/e600e044a770d29d1fe5d9638b274a7d4f22f969)
  - Not sure why CI was green, but it breaks tons of tests, see https://hud.pytorch.org/hud/pytorch/pytorch/930b575389f9233efddf70ea7b7804ed06af80d5/1?per_page=50&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/155354#issuecomment-2998780884))
- [Revert "[Draft][CUDA] Use runtime driver API for cuStreamWriteValue32 (#156097)"](https://github.com/pytorch/pytorch/commit/e583b888194c8c74ebbd332c09c394acebbbbcff)
  - internal breakage ([comment](https://github.com/pytorch/pytorch/pull/156097#issuecomment-2997314638))
- [Revert "Enable Leak Sanitizer (#154584)"](https://github.com/pytorch/pytorch/commit/f5e1b24945cf7852a1425923ca543e1f83be14b1)
  - Need to suppress more output ([comment](https://github.com/pytorch/pytorch/pull/154584#issuecomment-2995792265))
- [Revert "Use CMake wholearchive group (#156393)"](https://github.com/pytorch/pytorch/commit/4f70fbbd16d1f0d62af082246a95e56cffccc860)
  - This PR is breaking XPU windows build. ([comment](https://github.com/pytorch/pytorch/pull/156393#issuecomment-2995576362))

### Weird (1)

- [Revert "Use official CUDAToolkit module in CMake (#154595)"](https://github.com/pytorch/pytorch/commit/b1d62febd03ac421197d5516596f98d3c46e9b44)
  - It breaks on some local setup with no clear diagnostic, but looks like it fails to find cuFile ([comment](https://github.com/pytorch/pytorch/pull/154595#issuecomment-2997959344))
