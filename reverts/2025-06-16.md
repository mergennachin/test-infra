# Week of 2025-06-16 to 2025-06-23 (41)

### GHFirst (8)

- [Revert "[ROCm] Bump AOTriton to 0.10b (#156290)"](https://github.com/pytorch/pytorch/commit/1036f6d114bc22a9b4cf620cf7f8364ea2fd7a60)
  - failing multiple internal tests ([comment](https://github.com/pytorch/pytorch/pull/156290#issuecomment-2992072727))
- [Revert "Upgrade to DLPack 1.0. (#145000)"](https://github.com/pytorch/pytorch/commit/b4442f42a93390760bb923cbe13b80993f5e8e78)
  - failing internal tests ([comment](https://github.com/pytorch/pytorch/pull/145000#issuecomment-2992055400))
- [Revert "[cuDNN][64-bit indexing] update conv depthwise 64bit indexing dispatch condition to match native kernel (#156140)"](https://github.com/pytorch/pytorch/commit/317af4c87b7b8b03b8a08a4ead84d4065dd920e0)
  - breaks internal builds ([comment](https://github.com/pytorch/pytorch/pull/156140#issuecomment-2988441548))
- [Revert "Refine alignment check along dynamic dimension for grouped MMs (#155466)"](https://github.com/pytorch/pytorch/commit/0b62465b99b23cb4afcd07424676cce34a676041)
  - breaks internal builds ([comment](https://github.com/pytorch/pytorch/pull/155466#issuecomment-2988285117))
- [Revert "[inductor][cutlass] binary remote cache (#156106)"](https://github.com/pytorch/pytorch/commit/ec08eb8ba22e66b113e4f2aba1f6afb738f9d861)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/156106#issuecomment-2981533904))
- [Revert "[Cutlass] Fix buffer missing issues (#155897)"](https://github.com/pytorch/pytorch/commit/35ecd7c2d44a4e370e21ddab76b6c28266188846)
  - failing internal tests ([comment](https://github.com/pytorch/pytorch/pull/155897#issuecomment-2978391416))
- [Revert "Unify dynamic shapes APIs naming 2 (expect_true and check) (#155776)"](https://github.com/pytorch/pytorch/commit/503362d019b3782581492af7767945dbd75ca1c9)
  - failing internal build ([comment](https://github.com/pytorch/pytorch/pull/155776#issuecomment-2977041192))
- [Revert "[cuBLASLt][cuBLAS] Support 2D bias and `beta != 1.0` in cuBLASLt (#154170)"](https://github.com/pytorch/pytorch/commit/b8d96c3f78a27e193f4fa9580f8d28298c8180e3)
  - failing torchrec tests ([comment](https://github.com/pytorch/pytorch/pull/154170#issuecomment-2976990461))

### Ignored Signal (4)

- [Revert "[nativert] move layout planner algorithms to libtorch (#156508)"](https://github.com/pytorch/pytorch/commit/d846e213553621cb4581f1f36ac0023e528ddb65)
  - [GH job link](https://github.com/pytorch/pytorch/actions/runs/15793524714/job/44524067679) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/eab45643f22e58ee12d95d8b0162d51ca0a50801) ([comment](https://github.com/pytorch/pytorch/pull/156508#issuecomment-2993589983))
- [Revert "[PT2]load dense delta by trimming prefixes (#155872)"](https://github.com/pytorch/pytorch/commit/728cf6721e2996490922d0eacb23081953e45fc7)
  - Broke lint, internal has been backed out ([comment](https://github.com/pytorch/pytorch/pull/155872#issuecomment-2985542895))
- [Revert "[PT2][partitioners] raise getitems in partitioners to allow earlier release of buffers (#155809)"](https://github.com/pytorch/pytorch/commit/94f8679019ea4b1272f1ad58ad7cad87147cf5a7)
  - pr_time_benchmarks ([comment](https://github.com/pytorch/pytorch/pull/155809#issuecomment-2985022572))
- [Revert "[Docs] Convert to markdown to fix 155032 (#155520)"](https://github.com/pytorch/pytorch/commit/fa4f07b5b80bdcf99a1c7452de41939d2ab5886f)
  - breaks multiple test_quantization.py::TestQuantizationDocs::test_quantization_ ([comment](https://github.com/pytorch/pytorch/pull/155520#issuecomment-2981996091))

### Not through pytorchbot (1)

- [Revert "[dynamo] Weblink generation when unimplemented_v2() is called (#156033)" (#156546)](https://github.com/pytorch/pytorch/commit/a47ca4fc746a663c0e97d55a87815d0965d0a7e9)

### No Signal (27)

- [Revert "[dynamo] control one_graph behavior additionally through config (#154283)"](https://github.com/pytorch/pytorch/commit/b5c8b8d09f006b1b2911858882a56dfe6e325f36)
  - All of this is responsible for regression, see https://github.com/pytorch/pytorch/pull/156561 ([comment](https://github.com/pytorch/pytorch/pull/154283#issuecomment-2994242583))
- [Revert "[dynamo] add set_fullgraph decorator/context manager (#154289)"](https://github.com/pytorch/pytorch/commit/5e56db59d46e34e6b0e7b6e7a7bf213f01349969)
  - All of this is responsible for regression, see https://github.com/pytorch/pytorch/pull/156561 ([comment](https://github.com/pytorch/pytorch/pull/154283#issuecomment-2994242583))
- [Revert "[dynamo] fix set_fullgraph for nested calls (#154782)"](https://github.com/pytorch/pytorch/commit/c10eeb5bad7e2266edab165037b4f8e6b4a490fc)
  - All of this is responsible for regression, see https://github.com/pytorch/pytorch/pull/156561 ([comment](https://github.com/pytorch/pytorch/pull/154283#issuecomment-2994242583))
- [Revert "[dynamo] handle fullgraph toggle using nested torch.compile (#155166)"](https://github.com/pytorch/pytorch/commit/ee3d9969cc2d5482cd417e70572f25c2ae54776c)
  - All of this is responsible for regression, see https://github.com/pytorch/pytorch/pull/156561 ([comment](https://github.com/pytorch/pytorch/pull/154283#issuecomment-2994242583))
- [Revert "[BE][3/16] fix typos in torch/ (torch/_inductor/) (#156313)"](https://github.com/pytorch/pytorch/commit/f1331f3f1b43d1848341a0f0da66a13cb05570d0)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156313#issuecomment-2994171213))
- [Revert "[BE][4/16] fix typos in torch/ (torch/_dynamo/) (#156314)"](https://github.com/pytorch/pytorch/commit/5b427c92a88f23da9e1339819fe90aa3c74f11b4)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156313#issuecomment-2994171213))
- [Revert "[BE][5/16] fix typos in torch/ (torch/distributed/) (#156315)"](https://github.com/pytorch/pytorch/commit/145d4cdc1195195685647d40ca2137ad1940d9c8)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156313#issuecomment-2994171213))
- [Revert "[BE][6/16] fix typos in torch/ (#156316)"](https://github.com/pytorch/pytorch/commit/3f44fdc03d6b99bee9996358bec77b634af82dcb)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156313#issuecomment-2994171213))
- [Revert "[BE][7/16] fix typos in torch/ (torch/csrc/) (#156317)"](https://github.com/pytorch/pytorch/commit/035a68d25aad6ef22c10dcb01a47b0c1d1da7d5c)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156313#issuecomment-2994171213))
- [Revert "[BE][9/16] fix typos in torch/ (torch/csrc/) (#156319)"](https://github.com/pytorch/pytorch/commit/1d3bca40ed1f5394b0419b72891642e3d20791c6)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156313#issuecomment-2994171213))
- [Revert "[BE][11/16] fix typos in torch/ (torch/csrc/distributed/) (#156321)"](https://github.com/pytorch/pytorch/commit/4b55871e06d6bad54eac45e45a9af615d758a39f)
  - export/test_torchbind.py::TestCompileTorchbind::test_compile_error_on_input_aliasing_contents_backend_aot_eager [GH job link](https://github.com/pytorch/pytorch/actions/runs/15804799771/job/44548489912) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/c95f7fa874a3116f1067f9092456ee7281003614) ([comment](https://github.com/pytorch/pytorch/pull/156321#issuecomment-2994163667))
- [Revert "[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)"](https://github.com/pytorch/pytorch/commit/754c04aa062d8f3c0449aec4bbcaab00bfca4bf2)
  - regresses functorch_maml_omniglot ([comment](https://github.com/pytorch/pytorch/pull/154564#issuecomment-2992685744))
- [Revert "[BE] Make Eigen an optional dependency (#155955)"](https://github.com/pytorch/pytorch/commit/208ec60e72a63f366c757a5bc895089ceb323fcc)
  - need to revert eigen test ([comment](https://github.com/pytorch/pytorch/pull/155955#issuecomment-2992512124))
- [Revert "[BE][MPS] Refactor core matmul logic into matmul_core (#155969)"](https://github.com/pytorch/pytorch/commit/d309cd1d502eab8e9cb536876bf5eed88634eb41)
  - need to revert eigen test ([comment](https://github.com/pytorch/pytorch/pull/155969#issuecomment-2992502683))
- [Revert "[InductorBench] Fix accuracy validation logic for MPS (#156385)"](https://github.com/pytorch/pytorch/commit/96d082d06bda98addd4ad7903d315477404dc272)
  - Has some bug in error handling ([comment](https://github.com/pytorch/pytorch/pull/156385#issuecomment-2992441769))
- [Revert "[Precompile] Hook up backend="inductor"  (#155387)"](https://github.com/pytorch/pytorch/commit/edd45f3a020f892c17672cc2d08f64cb960006ad)
  - dynamo/test_precompile_context.py::PrecompileContextTests::test_basic [GH job link](https://github.com/pytorch/pytorch/actions/runs/15772892021/job/44464141039) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/2c68c3e8d5e9a235f5861be6486de4959f80c840) ([comment](https://github.com/pytorch/pytorch/pull/155387#issuecomment-2992044073))
- [Revert "[build] Create target for flash attention (#156235)"](https://github.com/pytorch/pytorch/commit/a8fe982993221048ee1665ce28add1b02888784d)
  - Weird, but seems to have broken trunk: test_jit_fuser_te.py::TestTEFuserDynamic::test_skip_grad_in_check [GH job link](https://github.com/pytorch/pytorch/actions/runs/15748768079/job/44390494621) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/6d02321472ee0761092166dd273eb3ec386cf0c0) ([comment](https://github.com/pytorch/pytorch/pull/156235#issuecomment-2987784207))
- [Revert "[Draft][CUDA] Use runtime driver API for cuStreamWriteValue32 (#156097)"](https://github.com/pytorch/pytorch/commit/bfccfa0b31221d5df0b263de5a41fb9f7c84b97d)
  - break internal tests ([comment](https://github.com/pytorch/pytorch/pull/156097#issuecomment-2985785811))
- [Revert "[dynamo] control one_graph behavior additionally through config (#154283)"](https://github.com/pytorch/pytorch/commit/ce3406817d50b3357fa644784cc84ff167ce40ce)
  - inductor/test_flex_decoding.py::TestFlexDecodingCUDA::test_do_not_trigger_dynamic_shapes_on_empty_block_mask_cuda GH job link HUD commit link ([comment](https://github.com/pytorch/pytorch/pull/154283#issuecomment-2984795214))
- [Revert "[dynamo] add set_fullgraph decorator/context manager (#154289)"](https://github.com/pytorch/pytorch/commit/c5d3e7a4ff460eed70b8443485a7e3568e87aee9)
  - inductor/test_flex_decoding.py::TestFlexDecodingCUDA::test_do_not_trigger_dynamic_shapes_on_empty_block_mask_cuda GH job link HUD commit link ([comment](https://github.com/pytorch/pytorch/pull/154289#issuecomment-2984774814))
- [Revert "[dynamo] fix set_fullgraph for nested calls (#154782)"](https://github.com/pytorch/pytorch/commit/408d9884b07cf7268961bae7138a6436916d4a43)
  - inductor/test_flex_decoding.py::TestFlexDecodingCUDA::test_do_not_trigger_dynamic_shapes_on_empty_block_mask_cuda GH job link HUD commit link ([comment](https://github.com/pytorch/pytorch/pull/154782#issuecomment-2984764330))
- [Revert "[dynamo] handle fullgraph toggle using nested torch.compile (#155166)"](https://github.com/pytorch/pytorch/commit/6201981f48a63329ef38f4665ebdbd22493f89fc)
  - inductor/test_flex_decoding.py::TestFlexDecodingCUDA::test_do_not_trigger_dynamic_shapes_on_empty_block_mask_cuda [GH job link](https://github.com/pytorch/pytorch/actions/runs/15726606697/job/44333233942) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/a6a3a441442a96f38d0771c985f753223cea2ba0) ([comment](https://github.com/pytorch/pytorch/pull/155166#issuecomment-2984751600))
- [Revert "[dynamo] raise hard error if error is encountered while tracing resume function prologue (#154564)"](https://github.com/pytorch/pytorch/commit/8f02161d1012143263fdbca47ee62983448e2c7e)
  - inductor/test_flex_decoding.py::TestFlexDecodingCUDA::test_do_not_trigger_dynamic_shapes_on_empty_block_mask_cuda [GH job link](https://github.com/pytorch/pytorch/actions/runs/15726606697/job/44333233942) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/a6a3a441442a96f38d0771c985f753223cea2ba0) ([comment](https://github.com/pytorch/pytorch/pull/154564#issuecomment-2984409088))
- [Revert "[MPS][Testing][BE] Fix samples for full_like (#156026)"](https://github.com/pytorch/pytorch/commit/03488d820c292b8ec4bfd9a4e25d5f28068c9375)
  - Sorry breaks MPS tests: test_ops.py::TestMathBitsCPU::test_neg_view_full_like_cpu_float64 [GH job link](https://github.com/pytorch/pytorch/actions/runs/15683608879/job/44182730620) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/2d832c9587fd99db295b62d0c9b459d509c19d06) ([comment](https://github.com/pytorch/pytorch/pull/156026#issuecomment-2977903074))
- [Revert "Implement guard collectives (#155558)"](https://github.com/pytorch/pytorch/commit/61b271e0f3f93209325dea9dccb1e97e7bc16b41)
  - Breaks CI, sorry: [GH job link](https://github.com/pytorch/pytorch/actions/runs/15683161593/job/44181274826) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/38e5e81e55fc5d85d6cf8a83c96c88578995e3fe) ([comment](https://github.com/pytorch/pytorch/pull/155558#issuecomment-2977871178))
- [Revert "[Quant][CPU] fix fake_quantize_per_tensor_affine of inf values (#155109)"](https://github.com/pytorch/pytorch/commit/e9fdaf8701b599fd943bb899639b5e8a4966b3c3)
  - Looks like it broke ROCM tests ([comment](https://github.com/pytorch/pytorch/pull/155109#issuecomment-2977428354))
- [Revert "[C10][CUDA] Eagerly create context on torch.cuda.set_device(device) call (#155900)"](https://github.com/pytorch/pytorch/commit/365ce465f393a6426b4ab3148da9a92445bf61d3)
  - causing some sort of hang? in test_distributed_spawn [GH job link](https://github.com/pytorch/pytorch/actions/runs/15678895788/job/44168117193) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/8142a0286016e63a0e91b5667e1fb1a5e868ffd7) note to self: bad TD ([comment](https://github.com/pytorch/pytorch/pull/155900#issuecomment-2977365699))

### Weird (1)

- [Revert "Implement guard collectives (#155558)"](https://github.com/pytorch/pytorch/commit/190f76fa313410df8dbb4111c586a516bf55515c)
  - Hmm, may be I'm looking at the wrong metric, but https://hud.pytorch.org/hud/pytorch/pytorch/c92f1075aaf3649f6368af2a3df9b5167f941b3f/1?per_page=50&name_filter=inductor_torchbench_cpu_smoke&mergeEphemeralLF=true shows that test started to pass after PR were reverted ([comment](https://github.com/pytorch/pytorch/pull/155558#issuecomment-2978337152))
