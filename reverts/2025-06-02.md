# Week of 2025-06-02 to 2025-06-09 (32)

### GHFirst (15)

- [Revert "[Inductor] Improve typing, and prepare for ABI-compatible AOTI C-shim dispatching (#154371)"](https://github.com/pytorch/pytorch/commit/95448b2ce61c3995ecdae0bfec655a5ef81a117d)
  - see henry's comment above.  This was reverted internally because it causes a memory leak and OOMs on AMD? ([comment](https://github.com/pytorch/pytorch/pull/154371#issuecomment-2954192879))
- [Revert "[Intel GPU] Make SDPA output has the same stride as Query. (#154340)"](https://github.com/pytorch/pytorch/commit/d3c8f36ba0daa17d7629bbcbd49808ddd4c66c1d)
  - This PR breaks hugging face E2E run on XPU. ([comment](https://github.com/pytorch/pytorch/pull/154340#issuecomment-2942954192))
- [Revert "[forward fix] add support for MemoryFormat after type tightening (#154658)"](https://github.com/pytorch/pytorch/commit/93012d2290ed3bf25ac3d17b348dea8f7cb65150)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/154658#issuecomment-2942752048))
- [Revert "Add randint_like tensor overload for high (#154899)"](https://github.com/pytorch/pytorch/commit/5130ac64f4f59d7903a77a6469d17119114acff8)
  - Failing internal tests see https://fburl.com/diff/bai044ob ([comment](https://github.com/pytorch/pytorch/pull/154899#issuecomment-2942740661))
- [Revert "[Cutlass] fp8 dynamic shapes test (#154829)"](https://github.com/pytorch/pytorch/commit/6f93ce3c868b36e14097a7f91d3f52de5d4d63ab)
  - This is failing internal tests see, [fburl.com/diff/3gomp7i3](https://fburl.com/diff/3gomp7i3). Please re-land this as a co-dev diff ([comment](https://github.com/pytorch/pytorch/pull/154829#issuecomment-2940494361))
- [Revert "[Cutlass] EVT dynamic shapes support (#154835)"](https://github.com/pytorch/pytorch/commit/3fa3dbdb1fb12ccf67d9c094bb7ec088e4d31039)
  - This is part of a stack that is failing internal tests see, [fburl.com/diff/3gomp7i3](https://fburl.com/diff/3gomp7i3). Please re-land this as a co-dev diff ([comment](https://github.com/pytorch/pytorch/pull/154835#issuecomment-2940463211))
- [Revert "[dynamo] Mark a vt unspecialized nn module variable source earlier (#154780)"](https://github.com/pytorch/pytorch/commit/a99a01a677f859bc9800730927c8b7ae4adf7e41)
  - This fails internal testing see, https://fburl.com/diff/b0yuxk4w ([comment](https://github.com/pytorch/pytorch/pull/154780#issuecomment-2940381691))
- [Revert "[dynamo][dynamic] Recompilation hint for nn module integer attributes (#154867)"](https://github.com/pytorch/pytorch/commit/a0f2544502831e21e577313d563a3edb4ea98b15)
  - This fails internal testing see, https://fburl.com/diff/b0yuxk4w ([comment](https://github.com/pytorch/pytorch/pull/154780#issuecomment-2940381691))
- [Revert "[BE][Ez]: Fully type nn.utils.clip_grad (#154801)"](https://github.com/pytorch/pytorch/commit/50de6ae253601fb81df0e8e2eb1d06826066b567)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/154801#issuecomment-2937886337))
- [Revert "[dynamo] Record the pre-graph bytecode using fast record function event (#154769)"](https://github.com/pytorch/pytorch/commit/a7e496a8968c5a475538f807f20f4da3d154c856)
  - This fails internal tests see [fburl.com/diff/67gyp7gp](https://fburl.com/diff/67gyp7gp) ([comment](https://github.com/pytorch/pytorch/pull/154769#issuecomment-2933629894))
- [Revert "[dynamo][guards] Flush cache to more accurately measure guard overhead (#154764)"](https://github.com/pytorch/pytorch/commit/b86aaaae0bdda046bac4e01a8ac85e1e3d8a7a3e)
  - This fails internal tests see [fburl.com/diff/67gyp7gp](https://fburl.com/diff/67gyp7gp) ([comment](https://github.com/pytorch/pytorch/pull/154769#issuecomment-2933629894))
- [Revert "[Inductor] Add attention pattern for model DistilBert in transformers==4.44.2. (#154091)"](https://github.com/pytorch/pytorch/commit/37eb909c94aac0631b2e6e6805036a721474362c)
  - I root caused this PR to some failures, I tried to resolve with https://github.com/pytorch/pytorch/pull/154923 but it looks like there are more failures with my fix ([comment](https://github.com/pytorch/pytorch/pull/154091#issuecomment-2932848880))
- [Revert "[Inductor UT] Reuse test_fused_attention.py for Intel GPU. (#154110)"](https://github.com/pytorch/pytorch/commit/ac65e94f450c677dcb429aa15f6aafdd90a38818)
  - This is part of a stack with failures internally, I tried to resolve with https://github.com/pytorch/pytorch/pull/154923 but it looks like there are more failures ([comment](https://github.com/pytorch/pytorch/pull/154110#issuecomment-2932845168))
- [Revert "[inductor] Add kernel_hash_key to ChoiceCaller (#154470)"](https://github.com/pytorch/pytorch/commit/69e22301da75b01c3c8650acc9be6a459cb8c8e6)
  - Failing internal inductor tests, author is aware and suggested revert. D75767762 ([comment](https://github.com/pytorch/pytorch/pull/154470#issuecomment-2931717432))
- [Revert "[BE] Cleanup old ExecuTorch codegen and runtime code (#154165)"](https://github.com/pytorch/pytorch/commit/67067512a19070b80b5d420088595bdf9b0542e6)
  - This is failing when attempting to test against executorch main internally, author has acknowledged that this should be reverted ([comment](https://github.com/pytorch/pytorch/pull/154165#issuecomment-2931489616))

### Ignored Signal (2)

- [Revert "Add pinned numpy and fix build (#155129)"](https://github.com/pytorch/pytorch/commit/d3d64c6db090ee9be051202e6ac6fd4acd5d3e97)
  - Broke test_spectral_op, looks like missing xfail, see https://hud.pytorch.org/hud/pytorch/pytorch/0db3e0cf29604dae1007a678603e4dffd1c57562/1?per_page=50&name_filter=linux-jammy-py3.9-gcc11&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/155129#issuecomment-2947951632))
- [Revert "Inductor logging + analysis of torch.profile (#149697)"](https://github.com/pytorch/pytorch/commit/5e034334430f02adad6f9d7f2c40312d28a143c8)
  - Broke rocm, see https://hud.pytorch.org/hud/pytorch/pytorch/642687af29718dbb75f6f38f4370a2f9bfd37348/1?per_page=50&name_filter=linux-jammy-rocm&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/149697#issuecomment-2942415600))

### No Signal (13)

- [Revert "[inductor] use int64 for large index (#154575)"](https://github.com/pytorch/pytorch/commit/27df0c56b7c6b75a5f77f5714aeef2ef8f1faa2c)
  - broke inductor/test_op_dtype_prop.py::TestCaseCUDA::test_op_dtype_propagation_add_cuda_int32 [GH job link](https://github.com/pytorch/pytorch/actions/runs/15510656657/job/43673763835) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/2596e3d0617852469241be8777cf46db5c83928c), note for self: bad TD ([comment](https://github.com/pytorch/pytorch/pull/154575#issuecomment-2954175761))
- [Revert "[inductor] Add typing to _inductor/ir.py (#149958)"](https://github.com/pytorch/pytorch/commit/7e4c097b0752ae79a8b5dd1de21a51aaafba2ef9)
  - Looks like it broke inductor_torchbind tests, due to more graphbreaks, see https://hud.pytorch.org/hud/pytorch/pytorch/b0fbbef1361ccaab8a5aec8e7cd62150e7b361de/1?per_page=50&name_filter=linux-jammy-py3.13&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/149958#issuecomment-2949583209))
- [Revert "Turn on new tiling by default (#154768)"](https://github.com/pytorch/pytorch/commit/b0fbbef1361ccaab8a5aec8e7cd62150e7b361de)
  - Looks like it broke inductor CPU, see https://hud.pytorch.org/hud/pytorch/pytorch/231eb9902ba78a4ef70203243058f3c7c0ced15d/1?per_page=50&name_filter=inductor-triton-cpu&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/154768#issuecomment-2949468396))
- [Revert "[BE] Update cudnn to 9.10.1.4 (#155122)"](https://github.com/pytorch/pytorch/commit/9656251bb1bee12c0e2f21828dc14a4c3c06afdd)
  - Looks like it breaks a bunch of tests, see https://hud.pytorch.org/hud/pytorch/pytorch/36a722e20d081c1a5a6df417d0f8333f6c082476/1?per_page=50&name_filter=sm89&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/155122#issuecomment-2949209801))
- [Revert "Add dont constant fold flag (#154945)"](https://github.com/pytorch/pytorch/commit/05dd638ee98b36254c84095894c36fd0e7d95544)
  - This broke halide test sanity, see https://hud.pytorch.org/hud/pytorch/pytorch/a3098a74d494020dbb906c05ef047013e1921662/1?per_page=50&name_filter=halide&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/154945#issuecomment-2945598901))
- [Revert "Add CPython generator/contextlib tests (#150796)"](https://github.com/pytorch/pytorch/commit/a1057cda31fe890d237fe9a2e6b3314cd4be3439)
  - This is breaking tests on trunk. https://hud.pytorch.org/hud/pytorch/pytorch/main/1?per_page=50&name_filter=3.13&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/150796#issuecomment-2944469866))
- [Revert "[reland][dynamo] Record the pre-graph bytecode using fast record function event (#154974)"](https://github.com/pytorch/pytorch/commit/e01fde82131c7f0b4c122222694911ee6fab36ca)
  - Broke inductor tests, see https://hud.pytorch.org/hud/pytorch/pytorch/3c72b9fd8feed4588a040bc681ffe83cc7acd26d/1?per_page=50&name_filter=inductor%20%2F%20unit&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/154974#issuecomment-2944370617))
- [Revert "SDPA support gfx950 (#155103)"](https://github.com/pytorch/pytorch/commit/3c72b9fd8feed4588a040bc681ffe83cc7acd26d)
  - looks like it broke mi300 tests, see https://hud.pytorch.org/hud/pytorch/pytorch/9a4c08ddfc9b43c07cd16355277d359dfcef50d6/1?per_page=50&name_filter=mi300&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/155103#issuecomment-2944331460))
- [Revert "[test][dynamo] skip test_deopt_from_append_list on python>=3.13.3 (#155167)"](https://github.com/pytorch/pytorch/commit/523b637cbeb69665072a2cf489ec1c5313b57670)
  - This broke a bunch of 3.13 tests, see https://hud.pytorch.org/hud/pytorch/pytorch/fa3c38c7ae17b8d8fccd0958831f9f1ced9e46b3/1?per_page=50&name_filter=3.13&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/155167#issuecomment-2944318067))
- [Revert "Inductor unit tests: cuda 12.6 -> 12.8 (#155056)"](https://github.com/pytorch/pytorch/commit/f60b2712dd82e5da859057b93825d5b6d992d15c)
  - This broke a bunch of 3.13 tests, see https://hud.pytorch.org/hud/pytorch/pytorch/fa3c38c7ae17b8d8fccd0958831f9f1ced9e46b3/1?per_page=50&name_filter=3.13&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/155167#issuecomment-2944318067))
- [Revert "Always set CPU affinity for benchmark jobs (#154569)"](https://github.com/pytorch/pytorch/commit/4405dc148741d8516d58ab9716ea5a9ee7510527)
  - potentially causing compile time regressions, unsure ([comment](https://github.com/pytorch/pytorch/pull/154569#issuecomment-2940737778))
- [Revert "Remove AttributeError constructor (#154808)"](https://github.com/pytorch/pytorch/commit/ef92653022f66fe64001af8e8f7dd80a7a8f666a)
  - Need format code ([comment](https://github.com/pytorch/pytorch/pull/154808#issuecomment-2933286113))
- [Revert "Add CPython exception tests (#150789)"](https://github.com/pytorch/pytorch/commit/e3af628b0d379c8bbc9741161f663ec1db3d447b)
  - This is failing upstream in trunk, see https://hud.pytorch.org/pytorch/pytorch/commit/67fb9b7cc3f7d2ebbb104296f2b11776f4adbb22 ([comment](https://github.com/pytorch/pytorch/pull/150789#issuecomment-2932823586))

### Weird (2)

- [Revert "Add Intel GPU info collection to the collect env script (#137846)"](https://github.com/pytorch/pytorch/commit/0db3e0cf29604dae1007a678603e4dffd1c57562)
  - Breaks doc test, but should be easily fixable ([comment](https://github.com/pytorch/pytorch/pull/137846#issuecomment-2947935940))
- [Revert "Add __main__ guards to jit tests (#154725)"](https://github.com/pytorch/pytorch/commit/20912673a6c0e6a54f279699681a6754fb1e90f6)
  - This added 2nd copy of raise_on_run to common_utils.py which caused lint failures, see https://github.com/pytorch/pytorch/actions/runs/15445374980/job/43473457466 ([comment](https://github.com/pytorch/pytorch/pull/154725#issuecomment-2940503905))
