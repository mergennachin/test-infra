# Week of 2025-09-15 to 2025-09-22 (17)

### GHFirst (4)

- [Revert "Improve device info with new flops and bandwidth formula based on hardware libraries (#162245)"](https://github.com/pytorch/pytorch/commit/2a308c7dee73fa248629201ac2245042190cac56)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/162245#issuecomment-3313669412))
- [Revert "Fix boxcox to return same result for same input in one batch (#162772)"](https://github.com/pytorch/pytorch/commit/a3b68c7c57ae9299aa0544c8109d15b1000c1825)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/162772#issuecomment-3313213011))
- [Revert "remove unnecessary sync point in AveragedModel update (#158017)"](https://github.com/pytorch/pytorch/commit/a5419743c643f1c1c42f2d26feb7083187370a2c)
  - discussed with author - expecting this to break checkpointing ([comment](https://github.com/pytorch/pytorch/pull/158017#issuecomment-3301790645))
- [Revert "[Triton] [Inductor] Restrict subprocess autotuning to just Triton (#162688)"](https://github.com/pytorch/pytorch/commit/e13cf68d034ba6abcad4bd521eb188d51207b12b)
  - H100 tests didn't run internally for some reason, rerun with ciflow/h100 ([comment](https://github.com/pytorch/pytorch/pull/162688#issuecomment-3300634763))

### No Signal (11)

- [Revert "[ROCm] Bump FBGEMM commit to avoid CK errors (#162590)"](https://github.com/pytorch/pytorch/commit/607469bdad9da76e9a1226dd3df2bb49c1d1d0ec)
  - This breaks CUDA 13 builds ([comment](https://github.com/pytorch/pytorch/pull/162590#issuecomment-3313263772))
- [Revert "[dynamo][guards] Fail on an unknown framelocals to dict conversion (#162695)"](https://github.com/pytorch/pytorch/commit/32ad29b72a7714814007993f61024fcdb454229e)
  - internal failure at https://fburl.com/workplace/qiitdlp6 ([comment](https://github.com/pytorch/pytorch/pull/162695#issuecomment-3310757225))
- [Revert "[dynamo][guards] Do not construct entire framelocals dict for LAMBDA_GUARD (#162525)"](https://github.com/pytorch/pytorch/commit/1302637a2305372ab099b3e9da3534500f28341f)
  - internal tests fail ([comment](https://github.com/pytorch/pytorch/pull/162525#issuecomment-3310748980))
- [Revert "[CI] Move Windows build/tests to Python-3.10 (#162862)"](https://github.com/pytorch/pytorch/commit/17081209e5a4f24413551d8cd8df41ea1365faa6)
  - Breaks some windows tests ([comment](https://github.com/pytorch/pytorch/pull/162862#issuecomment-3310606135))
- [Revert "[BE] Update Python min version to 3.10 (#162310)"](https://github.com/pytorch/pytorch/commit/578047838cc5b32a9ac76900a414163a49705dec)
  - Breaks some windows tests ([comment](https://github.com/pytorch/pytorch/pull/162862#issuecomment-3310606135))
- [Revert "[CI] Update NVIDIA driver to `580.82.07` (#163111)"](https://github.com/pytorch/pytorch/commit/4ca3f435fbfcb2f4172e1e3ea073376a38651a25)
  - It started to fail now, but worked just fine in PR CI ([comment](https://github.com/pytorch/pytorch/pull/163111#issuecomment-3303707671))
- [Revert "[Reland] Return NoOpDeviceGuardImpl in replace of CudaDeviceGuard when device is not available, or cpu-only build (#163016)"](https://github.com/pytorch/pytorch/commit/79fd49742391b5b302c1befe42b29fe6981f71c2)
  - broke rocm CI, see export/test_export_opinfo.py::TestExportOnFakeCudaCUDA::test_fake_export_nonzero_cuda_float32 [GH job link](https://github.com/pytorch/pytorch/actions/runs/17787208381/job/50564369696) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/f1eb99e2e4363f20eb5896433e1eb7f7500aadea) ([comment](https://github.com/pytorch/pytorch/pull/163016#issuecomment-3303707552))
- [Revert "[ROCm] Remove HIPBLASLT_ALLOW_TF32 from codebase (#162998)"](https://github.com/pytorch/pytorch/commit/66308fb47071977c061b7131888698aa308c1cbf)
  - Sorry for reverting this, but it seems to break a slow cuda tests ([comment](https://github.com/pytorch/pytorch/pull/162998#issuecomment-3300280242))
- [Revert "[dynamo][hop] Introduce Local Map HOP (#161458)"](https://github.com/pytorch/pytorch/commit/e7c3f802ffa7db2bce3ba57e41ac1f7499a4b81a)
  - broke rocm tests ([comment](https://github.com/pytorch/pytorch/pull/161458#issuecomment-3299230458))
- [Revert "[BE] Make PyObjectSlot use a global PyInterpreter (#162659)"](https://github.com/pytorch/pytorch/commit/4db203f8759634206e9431042cb5b0c86afc3a52)
  - seems to have introduced errors in linting see https://github.com/pytorch/pytorch/actions/runs/17750689989/job/50444910643 ([comment](https://github.com/pytorch/pytorch/pull/162659#issuecomment-3298626136))
- [Revert "[lint][CI] Don't checkout submodules for lintrunner-noclang (#162844)"](https://github.com/pytorch/pytorch/commit/fa919feab6a55ea9104e4ce61d38c3725f5728e6)
  - seems to be needed after all - failing lint ([comment](https://github.com/pytorch/pytorch/pull/162844#issuecomment-3293465058))

### Weird (2)

- [Revert "[torch][cuda][device_limits] Library for querying device hardware limits for flops and bandwidth (#162942)"](https://github.com/pytorch/pytorch/commit/4b7aed89d82ac21bd9fb8358d8dbdcc64b0d213d)
  - Sorry for reverting your change but it needs some fixes for CUDA 13 ([comment](https://github.com/pytorch/pytorch/pull/162942#issuecomment-3308784448))
- [Revert "Set the credential to upload vLLM nightly wheels on schedule and workflow_dispatch (#163018)"](https://github.com/pytorch/pytorch/commit/d4554bc284663b9e55a2f6fcfb52eb565a042a37)
  - Missed another update on the environment ([comment](https://github.com/pytorch/pytorch/pull/163018#issuecomment-3300444271))
