# Week of 2025-07-14 to 2025-07-21 (31)

### GHFirst (11)

- [Revert "[Easy] Show some clear error when torch.ops.load_library fails. (#157524)"](https://github.com/pytorch/pytorch/commit/c2c88846a9c75185660f3b2a8b72c3aa2f8ae3dc)
  - reverting for now to reopen the discussion ([comment](https://github.com/pytorch/pytorch/pull/157524#issuecomment-3091317252))
- [Revert "Add warning about removed sm50 and sm60 arches (#158301)"](https://github.com/pytorch/pytorch/commit/5b40f6581eac8a2e92af8dd986df7c22ad4584ce)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/158301#issuecomment-3091307023))
- [Revert "Cleanup old caffe2 scripts (#158475)"](https://github.com/pytorch/pytorch/commit/ced5cf042de1d4b573f258c9f770581d9574b990)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/158475#issuecomment-3085447409))
- [Revert "[cuDNN][SDPA] cuDNN SDPA refactor/cleanup, nested tensor backward, test priority bump for `sm90`, `sm100` (#149282)"](https://github.com/pytorch/pytorch/commit/bfe5674e2294a6c73ff671116a91f6ae7220b3f8)
  - reverting as discussed with @drisspg - @eqy please reach out to @drisspg for more info  ([comment](https://github.com/pytorch/pytorch/pull/149282#issuecomment-3084759671))
- [Revert "recovering node source from dict (#158373)"](https://github.com/pytorch/pytorch/commit/14ecc0336185f2ca5591858bc74cd4aadf2d1161)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/158373#issuecomment-3080093479))
- [Revert "Introduce AcceleratorAllocatorConfig as the common class (#149601)"](https://github.com/pytorch/pytorch/commit/46915b13614dbac90724d0f1802b8e0db037c9e4)
  - See https://github.com/pytorch/pytorch/pull/149601#discussion_r2208325379 ([comment](https://github.com/pytorch/pytorch/pull/149601#issuecomment-3074965720))
- [Revert "Refactor CUDAAllocatorConfig to reuse AcceleratorAllocatorConfig (#150312)"](https://github.com/pytorch/pytorch/commit/41971335c98b0881e0784085096eceace575d563)
  - Sorry for reverting your change but because https://github.com/pytorch/pytorch/pull/157908 has been reverted + this PR caused issue earlier, I think it is better to revert the whole stack and reland it from scratch to be sure ([comment](https://github.com/pytorch/pytorch/pull/150312#issuecomment-3074897532))
- [Revert "Deprecate overleap functions in CUDAAllocatorConfig, use AcceleratorAllocatorConfig instead (#156165)"](https://github.com/pytorch/pytorch/commit/ea5f88dca62b996cc8d081b14435d3d4392e043e)
  - Sorry for reverting your change but because https://github.com/pytorch/pytorch/pull/157908 has been reverted + this PR caused issue earlier, I think it is better to revert the whole stack and reland it from scratch to be sure ([comment](https://github.com/pytorch/pytorch/pull/150312#issuecomment-3074897532))
- [Revert "Enable AcceleratorAllocatorConfig key check (#157908)"](https://github.com/pytorch/pytorch/commit/f2ecf6145fde55baa8a91e27b6b3489172f0e639)
  - Sorry for reverting your change but it is failing internally per https://github.com/pytorch/pytorch/pull/157908#discussion_r2208204782 ([comment](https://github.com/pytorch/pytorch/pull/157908#issuecomment-3074833696))
- [Revert "Refactor CUDAAllocatorConfig to reuse AcceleratorAllocatorConfig (#150312)"](https://github.com/pytorch/pytorch/commit/6fe7456aa1a2d025d1d06e15ba3896e6adba94b8)
  - Sorry for reverting your change but it is failing to build PyTorch internally ([comment](https://github.com/pytorch/pytorch/pull/150312#issuecomment-3070218901))
- [Revert "Deprecate overleap functions in CUDAAllocatorConfig, use AcceleratorAllocatorConfig instead (#156165)"](https://github.com/pytorch/pytorch/commit/e8cca7bac7553af0efe208d40c1cbaab72797ad9)
  - Sorry for reverting your change but it is failing to build PyTorch internally ([comment](https://github.com/pytorch/pytorch/pull/150312#issuecomment-3070218901))

### Ignored Signal (4)

- [Revert "Support DeepSeek-style blockwise scaling scaled-mm for fp8 on Hopper+ (#158037)"](https://github.com/pytorch/pytorch/commit/32aade9d8d39d58c33215f50afe5382458d70821)
  - Ignored ROCm failures while ROCm was unstable, but HUD clearly shows this PR introduced failures on trunk ([comment](https://github.com/pytorch/pytorch/pull/158037#issuecomment-3087982975))
- [Revert "Add torch compile force disable caches alias (#158072)"](https://github.com/pytorch/pytorch/commit/9a7c2f1f64b1dba1df9ca12249ef659394ffe13d)
  - fails on rocm, signal ignored while rocm was unstable ([comment](https://github.com/pytorch/pytorch/pull/158072#issuecomment-3086740829))
- [Revert "Unify torch.tensor and torch.ops.aten.scalar_tensor behavior (#158537)"](https://github.com/pytorch/pytorch/commit/813c76b98d5bffbffb087502c4f02a043b924d59)
  - This broke C++ tests ([comment](https://github.com/pytorch/pytorch/pull/158537#issuecomment-3084425920))
- [Revert "Support DeepSeek-style blockwise scaling scaled-mm for fp8 on Hopper+ (#158037)"](https://github.com/pytorch/pytorch/commit/9513b9d03fa8950ba5d2b59cc0b1a1aab3a41c06)
  - OSX failures are real ([comment](https://github.com/pytorch/pytorch/pull/158037#issuecomment-3079042171))

### Landrace (2)

- [Revert "[DTensor] Fix default_strategy and rename for clarity (#158490)"](https://github.com/pytorch/pytorch/commit/bf4aa7827905a2fca96bf266b242a7a16e489af4)
  - broke lint? [GH job link](https://github.com/pytorch/pytorch/actions/runs/16361950974/job/46231492581) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/d8b084312b54e97bdbaf6a178fe2fc628a23243b) ([comment](https://github.com/pytorch/pytorch/pull/158490#issuecomment-3090042448))
- [Revert "[DTensor] fix copy_ strategy (#158538)"](https://github.com/pytorch/pytorch/commit/50f33a6fca88cd04b79760483e69a73b5eabe25e)
  - broke lint? [GH job link](https://github.com/pytorch/pytorch/actions/runs/16361950974/job/46231492581) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/d8b084312b54e97bdbaf6a178fe2fc628a23243b) ([comment](https://github.com/pytorch/pytorch/pull/158490#issuecomment-3090042448))

### Not through pytorchbot (1)

- [Revert "[PT2][fusion] ban fusions with large accumulated reads (#157563) (#158550)](https://github.com/pytorch/pytorch/commit/7ebbf2cae7e55d5f64a15a1e8912e55ff0a6c9a4)

### No Signal (10)

- [Revert "Fix test consolidate hf safetensors (#157386)"](https://github.com/pytorch/pytorch/commit/3bb729df97ed632e4629b706eb18a30dffebc310)
  - Need to revert this so we can revert PR 156705, which introduced errors on ROCm CI. These errors were not seen on CUDA CI because CUDA CI docker images do not have safetensors installed and the test silently passes ([comment](https://github.com/pytorch/pytorch/pull/157386#issuecomment-3090706074))
- [Revert "[DCP][HF] [ez]Change where sharded tensors are saved (#158069)"](https://github.com/pytorch/pytorch/commit/e3351b3ddff06c90b2786b23312f80fda2ddb4a6)
  - Didn't remove reference to `consolidated_output_path` in test_hf_safetensor_e2e.py; CUDA runs do not surface issue because safetensors is not installed and the test silently passes ([comment](https://github.com/pytorch/pytorch/pull/158069#issuecomment-3090692336))
- [Revert "[ROCm][CI] update fbgemm_gpu hash used by inductor tests (#158602)"](https://github.com/pytorch/pytorch/commit/86675af3f02e54fed4bbae68d6316274b93b373f)
  - The lint job failure was hiding a real lint failure. See here for more details: [GH job link](https://github.com/pytorch/pytorch/actions/runs/16375911199/job/46275682191) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/6f73e067963e31d16840fbc34993a64cee698746) ([comment](https://github.com/pytorch/pytorch/pull/158602#issuecomment-3090209891))
- [Revert "DDE-Free select with unbacked index. (#157605)"](https://github.com/pytorch/pytorch/commit/23550ab735eee1b9cc90609788dc64ccfb242af2)
  - fail pr time benchmarks  ([comment](https://github.com/pytorch/pytorch/pull/157605#issuecomment-3084663020))
- [Revert "Move off of deprecated API in 2.9 (#158527)"](https://github.com/pytorch/pytorch/commit/288bf54a23a49dd3b765b4e1c7313c706b46a08a)
  - breaks trunk ([comment](https://github.com/pytorch/pytorch/pull/158527#issuecomment-3084385585))
- [Revert "[Docker builds] Move from Miniconda to Miniforge (#158370)"](https://github.com/pytorch/pytorch/commit/9f37cce69334bccebf4b21503f0047d0c0bb320c)
  - this fail pr time benchmarks ([comment](https://github.com/pytorch/pytorch/pull/158370#issuecomment-3082744071))
- [Revert "[cuda][cupy] Improve cupy device placement when device is provided (#158320)"](https://github.com/pytorch/pytorch/commit/944a140e90389eced1ec38e14cb4345811ed0b1a)
  - reverting because most likely causing test/test_numba_integration.py::TestNumbaIntegration::test_from_cuda_array_interface_inferred_strides to fail ([comment](https://github.com/pytorch/pytorch/pull/158320#issuecomment-3079960616))
- [Revert "[ROCm] logsumexp on ROCm needs scaling back to natural base. (#156903)"](https://github.com/pytorch/pytorch/commit/03852ddc22350eb8b6ed6b61777639ce6080f3dc)
  - Breaks torchao and torchtitan nightly builds ([comment](https://github.com/pytorch/pytorch/pull/156903#issuecomment-3076423488))
- [Revert "[CI] Fixes CI for CUDA Version > 12.9 (#157385)"](https://github.com/pytorch/pytorch/commit/b26da7741be37693ab1cd21115f3fca15b1cdb6b)
  - broke some slow tests test_cpp_extensions_jit.py::TestCppExtensionJIT::test_jit_cuda_archflags [GH job link](https://github.com/pytorch/pytorch/actions/runs/16286465717/job/45986677885) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/6c5227ba00a2904365af566c24b4681cd01a041c) ([comment](https://github.com/pytorch/pytorch/pull/157385#issuecomment-3074737541))
- [Revert "[Inductor] Set the default value of min_chunk_size to 512 (#150762)"](https://github.com/pytorch/pytorch/commit/6ea91f067256447cda6fae533f806c1f8baafbe2)
  - Sorry for reverting your change, but an inductor compilation error shows up in trunk ([comment](https://github.com/pytorch/pytorch/pull/150762#issuecomment-3070286787))

### Weird (3)

- [Revert "Forward-fix unused variables warning/error (#158549)"](https://github.com/pytorch/pytorch/commit/be896d6b41f560e59c87f9d28df109b1553139a4)
  - Sorry, need to revert this first, so we can revert PR 158037, which broke ROCm CI ([comment](https://github.com/pytorch/pytorch/pull/158549#issuecomment-3087942475))
- [Revert "[PT2][fusion] ban fusions with large accumulated reads (#157563)"](https://github.com/pytorch/pytorch/commit/26807dcf277feb2d99ab88d7b6da526488baea93)
  - broke test_linear_and_cel on main https://hud.pytorch.org/pytorch/pytorch/commit/c062550a3598d27c2d6572db7c0f4ff90a84cc84, caused OOM? Also broken on PR, Dr. CI classification is wrong (claims the test is disabled by an issue but the issue is for a different test).  Also I'm pretty sure the expected results json is supposed to have a ton of empty lines, its to prevent merge conflicts, I will add it to the linter ([comment](https://github.com/pytorch/pytorch/pull/157563#issuecomment-3074355331))
- [Revert "[simple_fsdp][inductor_collectives] rewrite reorder_collectives, sink_waits_iterative (#158062)"](https://github.com/pytorch/pytorch/commit/4f36743f5eef2d9c40357eb5d8d8b1aeeacfbb2a)
  - sorry I want to revert something else and this is causing a merge conflict, all you should need to do is rebase and remerged ([comment](https://github.com/pytorch/pytorch/pull/158062#issuecomment-3074342140))
