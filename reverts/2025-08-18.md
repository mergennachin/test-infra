# Week of 2025-08-18 to 2025-08-25 (28)

### GHFirst (8)

- [Revert "Enable output padding when only outermost dim is dynamic (#159404)"](https://github.com/pytorch/pytorch/commit/710514a2a51facaba445d2c188541d778f9fdb59)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/159404#issuecomment-3216517032))
- [Revert "[dynamic shapes] unbacked-safe slicing (#157944)"](https://github.com/pytorch/pytorch/commit/3f1a97a99cad4cc682b20b43c1178ed9e1b81f24)
  - this PR & internal diff landed out of sync, just reverted internal with D80720654, will revert this & reland as codev ([comment](https://github.com/pytorch/pytorch/pull/157944#issuecomment-3215610135))
- [Revert "[Inductor] Update Outer Reduction Heuristic (#159093)"](https://github.com/pytorch/pytorch/commit/1d458e294755ff2bfa314c67ddc5cb1dacc2aee8)
  - this fails internal tests, see D80630416 for more info ([comment](https://github.com/pytorch/pytorch/pull/159093#issuecomment-3215263317))
- [Revert "[ATen][CPU][Sparse] Use Third-Party Eigen for sparse add and addmm (#155357)"](https://github.com/pytorch/pytorch/commit/fc0683b1e75fdf3182e0855b3f79e80fe0124ef1)
  - This is causing buck builds to fail since we didn't add the definition of AT_USE_EIGEN_SPARSE in the buckbuild.bzl file, will follow-up and re-land this. ([comment](https://github.com/pytorch/pytorch/pull/155357#issuecomment-3212270510))
- [Revert "flip the list-as-tuple behavior for short lists (#160794)"](https://github.com/pytorch/pytorch/commit/a6401cb5aa51622045c3f9a03b2cebef236e4182)
  - This if failing internal tests, see D80671241 ([comment](https://github.com/pytorch/pytorch/pull/160794#issuecomment-3211314867))
- [Revert "[dynamic shapes] unbacked-safe slicing (#157944)"](https://github.com/pytorch/pytorch/commit/6ea4be1e2eca952ea66090182bd2eede89799a45)
  - This is blocking internal sync due to merge conflicts ([comment](https://github.com/pytorch/pytorch/pull/157944#issuecomment-3206833193))
- [Revert "Recheck Autotune cache on Precompile serialization to prune compilation results (#158656)"](https://github.com/pytorch/pytorch/commit/eddaaa6c2a66a84e17b17bf8af5131852067b259)
  - failing internal tests, see D80486843 ([comment](https://github.com/pytorch/pytorch/pull/158656#issuecomment-3201491561))
- [Revert "[ONNX] Default to dynamo export (#159646)"](https://github.com/pytorch/pytorch/commit/82c7a1eb4b743408e907bdd09ea5645af964ae85)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/159646#issuecomment-3198507767))

### Ignored Signal (1)

- [Revert "Use numpy 1.26.2 for Python 3.9 and 3.10 (#160836)"](https://github.com/pytorch/pytorch/commit/e3ebf364e6d2fb8008da113a596d3cc426ba9c79)
  - It broke inductor tests by improving them ([comment](https://github.com/pytorch/pytorch/pull/160836#issuecomment-3200834103))

### Landrace (2)

- [Revert "[inductor] Estimate peak memory allocfree and applying to reordering collectives (#160113)"](https://github.com/pytorch/pytorch/commit/7006fd0c8874cb0228d3f2bfd83a989bde4b7021)
  - Segment tree starts failing on trunk even ciflows/trunk passed on PR ([comment](https://github.com/pytorch/pytorch/pull/160113#issuecomment-3211286092))
- [Revert "[inductor] Estimate peak memory allocfree and applying to reordering collectives (#160113)"](https://github.com/pytorch/pytorch/commit/bd5857a1d6d5455d4f0057c182dff5e8ad2a4c8a)
  - Sorry for reverting your change, but lots of failures showing up after this lands ([comment](https://github.com/pytorch/pytorch/pull/160113#issuecomment-3209487237))

### Not through pytorchbot (1)

- [Back out "Deprecate overleap functions in CUDAAllocatorConfig, use AcceleratorAllocatorConfig instead (#156165)" (#160999)](https://github.com/pytorch/pytorch/commit/a818fa77e3a72271f144514ef349c5a666313205)

### No Signal (13)

- [Revert "Move non inductor workflows to Python 3.9 -> 3.10 (#161182)"](https://github.com/pytorch/pytorch/commit/f912c93344caa74e24c8164a2e25fe84a8203073)
  - broke dynamo_wrapped tests, those are a bit finicky to fix (there is probably more than one failure!) ([comment](https://github.com/pytorch/pytorch/pull/161182#issuecomment-3216953097))
- [Revert "[SymmMem] Support rendezvous on slice of a tensor (#160825)"](https://github.com/pytorch/pytorch/commit/47d267364cad407b5612bf4a5faa160d2f4a7121)
  - Change of course; use storage_ptr as key ([comment](https://github.com/pytorch/pytorch/pull/160825#issuecomment-3215951048))
- [Revert "Close some sources of fake tensor leakages  (#159923)"](https://github.com/pytorch/pytorch/commit/981ac533c6e69a77538aaa7a9747c3d840dfa8be)
  - broke aoti test in inductor periodic ([comment](https://github.com/pytorch/pytorch/pull/159923#issuecomment-3215580688))
- [Revert "[BE][inductor] tl.dot(..., allow_tf32=...) -> tl.dot(..., input_precision=...) (#160711)"](https://github.com/pytorch/pytorch/commit/2c0650a00a0a0dd2bbf25ed22780fdd881bcda54)
  - internal failure - T235384144 - I'll revert while I investigate. ([comment](https://github.com/pytorch/pytorch/pull/160711#issuecomment-3215343200))
- [Revert "[SymmMem] Support rendezvous on view of a tensor (#160925)"](https://github.com/pytorch/pytorch/commit/eba1ad09e47b66478f973e03cece7f314ac3b412)
  - Change of course: use storage ptr as symm mem keys as in the old days and force no_split in MemPool ([comment](https://github.com/pytorch/pytorch/pull/160925#issuecomment-3215315717))
- [Revert "[DTensor] Make default RNG semantics match user-passed generator (#160482)"](https://github.com/pytorch/pytorch/commit/c7a77470c54b28e555319e34048af14d1d66198a)
  - failing cuda and rocm jobs ([comment](https://github.com/pytorch/pytorch/pull/160482#issuecomment-3214694297))
- [Revert "cd: Add no-cache for test binaries (#149218)"](https://github.com/pytorch/pytorch/commit/639b8cc51ddebf10361f3840a6b0a244eb6092a1)
  - Lets not use no-cache flags on test binaries ([comment](https://github.com/pytorch/pytorch/pull/149218#issuecomment-3214338844))
- [Revert "[FSDP][Collectives] skipping reduce_scatter when world size is 1 (#160136)"](https://github.com/pytorch/pytorch/commit/f9875166a953a51bbd454d963ee03d41818a27e8)
  - Sorry, but looks like this broke ROCm distributed CI ([comment](https://github.com/pytorch/pytorch/pull/160136#issuecomment-3208632921))
- [Revert "[FSDP][Replicate] replicate tests for param registration and input device movements (#160147)"](https://github.com/pytorch/pytorch/commit/6b5be1f4a0a1c881b36fb952cdd56421f9f71786)
  - Sorry, but looks like this broke ROCm distributed CI ([comment](https://github.com/pytorch/pytorch/pull/160136#issuecomment-3208632921))
- [Revert "[rfc] add hint_override kwarg to mark_dynamic (#161007)"](https://github.com/pytorch/pytorch/commit/90ea9ccefe3e2d9a9e4840016d1af10c1814d48b)
  - failing on both cuda and rocm ([comment](https://github.com/pytorch/pytorch/pull/161007#issuecomment-3206893756))
- [Revert "[dynamic shapes] unbacked-safe slicing (#157944)"](https://github.com/pytorch/pytorch/commit/5e98d9f9bab96369672c057b4ef3fa1299c70383)
  - Sorry for reverting your change but I think this is failing test_draft_export in trunk https://hud.pytorch.org/pytorch/pytorch/commit/56218d85e2da09d9ede3809718ec989c2151632c ([comment](https://github.com/pytorch/pytorch/pull/157944#issuecomment-3198874677))
- [Revert "Remove guard_size_oblivious from default contiguity python check, and add aten.sym_is_contiguous. (#159197)"](https://github.com/pytorch/pytorch/commit/b82aa3df20bcef7695ed3261d3dc93fa942516ee)
  - internal build failures ([comment](https://github.com/pytorch/pytorch/pull/159197#issuecomment-3195436668))
- [Revert "Use numpy 1.26.2 for Python 3.9 and 3.10 (#160836)"](https://github.com/pytorch/pytorch/commit/3ced4f1e6cb37d3470dcc540892dee08a6019cf8)
  - broke some inductor jobs? Maybe just update the expected values? Not sure what the policy is for something like this [GH job link](https://github.com/pytorch/pytorch/actions/runs/17024529273/job/48262123844) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/7a68d02292fd7a430b55c5bce3268a33c7ec5055) ([comment](https://github.com/pytorch/pytorch/pull/160836#issuecomment-3194953213))

### Weird (3)

- [Revert "Fix torchaudio build when TORCH_CUDA_ARCH_LIST is not set (#161084)"](https://github.com/pytorch/pytorch/commit/acb00d3ccf5f2d566225f07ed66bd579d5d3e44e)
  - My mistake for not checking for nvidia-smi availability ([comment](https://github.com/pytorch/pytorch/pull/161084#issuecomment-3209498435))
- [Revert "handling special case for pow(3) for GPU (#157537)"](https://github.com/pytorch/pytorch/commit/e83825f91cb2901567fedbf31ba7cc434a897271)
  - This is really really bad from performance point of view, wonder if any benchmarks will detect that ([comment](https://github.com/pytorch/pytorch/pull/157537#issuecomment-3202661810))
- [Revert "[WIP] Merge Test (#160998)"](https://github.com/pytorch/pytorch/commit/eba20d2d748cb17dce9aa26e5513e4567bfd8282)
  - Undoing test merge ([comment](https://github.com/pytorch/pytorch/pull/160998#issuecomment-3202125839))
